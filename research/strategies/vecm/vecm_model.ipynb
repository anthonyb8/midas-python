{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/anthony/git-projects/midas')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from core.strategies.research import DataProcessing, TimeseriesTests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CointegrationStrategy:\n",
    "    def __init__(self, data:pd.DataFrame) -> None:\n",
    "        self.data = data # Timestamp | Asset1 | Asset2 structure\n",
    "\n",
    "    def create_spread(self,data:pd.DataFrame, cointegration_vector:list):\n",
    "        return data.dot(cointegration_vector)\n",
    "\n",
    "    def calculate_z_score(self,spread:pd.Series):\n",
    "        \"\"\"\n",
    "        Calculate the z-score of a given time series.\n",
    "\n",
    "        Args:\n",
    "        series (Series): A pandas Series representing the spread.\n",
    "\n",
    "        Returns:\n",
    "        Series: A pandas Series of the z-scores.\n",
    "        \"\"\"\n",
    "        return (spread - spread.mean()) / spread.std()\n",
    "\n",
    "    def visualize_spread_formula(self,data:pd.DataFrame, cointegration_vector:np.array):\n",
    "        \"\"\"\n",
    "        Visualize the formula for creating the spread using the cointegration vector.\n",
    "\n",
    "        Parameters:\n",
    "            data (pd.DataFrame): DataFrame containing the data with columns as tickers.\n",
    "            cointegration_vector (list): List representing the cointegration vector (hedge ratios).\n",
    "\n",
    "        Returns:\n",
    "            None (prints the formula)\n",
    "        \"\"\"\n",
    "        # Create a DataFrame to display the formula\n",
    "        formula_df = pd.DataFrame(columns=[\"Ticker\", \"Hedge Ratio\"])\n",
    "        \n",
    "        # Populate the DataFrame with tickers and corresponding hedge ratios\n",
    "        formula_df[\"Ticker\"] = data.columns\n",
    "        formula_df[\"Hedge Ratio\"] = cointegration_vector\n",
    "        \n",
    "        # Print the formula\n",
    "        print(\"Spread = \")\n",
    "        for index, row in formula_df.iterrows():\n",
    "            print(f\"({row['Hedge Ratio']} * {row['Ticker']}) + \", end=\"\")\n",
    "        print(\"Constant Term\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1 : Retrieve and prepare data\n",
    "start_date = \"2018-05-18\"\n",
    "end_date = \"2023-01-19\"\n",
    "# symbols = ['AAPL','MSFT']\n",
    "symbols = [\"HE.n.0\", \"ZC.n.0\"]#, \"HE.n.0\"]\n",
    "\n",
    "data_processing = DataProcessing()\n",
    "data = data_processing.get_data(symbols, start_date,end_date)\n",
    "Strategy = CointegrationStrategy(data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2 : Training and Testing Split\n",
    "data = data.ffill()\n",
    "# log_data = np.log(data)\n",
    "train_data,test_data = data_processing.split_data(data)\n",
    "data_processing.check_missing(train_data)\n",
    "print(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3 : Test for exponential nature (determine if log prices will be used)\n",
    "time_array = range(1, len(train_data) + 1)\n",
    "bp_results = {}\n",
    "\n",
    "for column in train_data.columns:\n",
    "    value_array = train_data[column].values\n",
    "    TimeseriesTests.line_plot(x=time_array, y=value_array)\n",
    "\n",
    "    residuals_linear, residuals_exp = data_processing.fit_and_compare(time_array, value_array)\n",
    "\n",
    "    bp_results[f\"{column}_linear_residual\"] = TimeseriesTests.breusch_pagan(np.array(residuals_linear), np.array(time_array))\n",
    "    constant_to_add = abs(residuals_exp.min()) + 1\n",
    "\n",
    "    # Adjust residuals and apply log transformation\n",
    "    adjusted_residuals_exp = np.log(np.abs(residuals_exp) + constant_to_add)\n",
    "\n",
    "    # Perform Breusch-Pagan test on adjusted residuals\n",
    "    bp_results[f\"{column}_exp_residual\"] = TimeseriesTests.breusch_pagan(np.array(time_array), np.array(adjusted_residuals_exp))\n",
    "\n",
    "\n",
    "TimeseriesTests.display_breusch_pagan_results(bp_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4 : Check stationarity\n",
    "adf_results = {}\n",
    "kpss_results = {}\n",
    "pp_results = {}\n",
    "\n",
    "\n",
    "for column in train_data.columns:\n",
    "    series = train_data[column]\n",
    "    adf_results[column] = TimeseriesTests.adf_test(series, trend='ct')\n",
    "    pp_results[column] = TimeseriesTests.phillips_perron_test(series, trend='ct')\n",
    "    # kpss_results[column] = TimeseriesTests.kpss_test(series, trend='ct')\n",
    "\n",
    "TimeseriesTests.display_adf_results(adf_results)\n",
    "TimeseriesTests.display_pp_results(pp_results)\n",
    "# TimeseriesTests.display_kpss_results(kpss_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5 : Check stationarity at first difference\n",
    "adf_results_diff = {}\n",
    "kpss_results_diff = {}\n",
    "pp_results_diff = {}\n",
    "\n",
    "for column in train_data.columns:\n",
    "    series = train_data[column].diff(1)\n",
    "    series.dropna(inplace=True)\n",
    "    adf_results_diff[f\"{column}_diff\"] = TimeseriesTests.adf_test(series)\n",
    "    pp_results_diff[f\"{column}_diff\"] = TimeseriesTests.phillips_perron_test(series, trend='ct')\n",
    "    # kpss_results_diff[f\"{column}_diff\"] = TimeseriesTests.kpss_test(series)\n",
    "\n",
    "TimeseriesTests.display_adf_results(adf_results_diff)\n",
    "TimeseriesTests.display_pp_results(pp_results_diff)\n",
    "# TimeseriesTests.display_kpss_results(kpss_results_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6 : Check seasonality\n",
    "seasonal_adf_results = {}\n",
    "\n",
    "for column in train_data.columns:\n",
    "    series = train_data[column]\n",
    "    seasonal_adf_results[f\"{column}_seasonality\"] = TimeseriesTests.seasonal_adf_test(series)\n",
    "\n",
    "TimeseriesTests.display_adf_results(seasonal_adf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 7 : Detemine lag length\n",
    "lag = TimeseriesTests.select_lag_length(data=data)\n",
    "print(f\"\\nIdeal Lag : {lag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 8 : Check cointegrations\n",
    "johansen_results, num_cointegrations = TimeseriesTests.johansen_test(data=train_data,k_ar_diff=lag-1)\n",
    "TimeseriesTests.display_johansen_results(johansen_results, num_cointegrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 9 : Check granger causality (Use differenced data as it needs to be stationary)\n",
    "data_diff = data.diff(1).dropna()\n",
    "granger_results = TimeseriesTests.granger_causality(data_diff, max_lag=4)\n",
    "TimeseriesTests.display_granger_results(granger_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10 : Build VECM\n",
    "model = TimeseriesTests.vecm_model(data=train_data, coint_rank=max(num_cointegrations,1), k_ar_diff=lag-1)\n",
    "residual_array = model.resid\n",
    "residuals = pd.DataFrame(residual_array, columns=train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11 : Validate Model (Residual Tests)\n",
    "\n",
    "# Test for Serial Correlation in Residuals\n",
    "ljung_box_results = TimeseriesTests.ljung_box(residuals, lags=lag)\n",
    "TimeseriesTests.display_ljung_box_results(ljung_box_results)\n",
    "\n",
    "durbin_watson_result = TimeseriesTests.durbin_watson(residuals)\n",
    "TimeseriesTests.display_durbin_watson_results(durbin_watson_result)\n",
    "\n",
    "# Test for Stationarity in Resiuals\n",
    "adf_residuals = {}\n",
    "kpss_residuals = {}\n",
    "pp_residuals = {}\n",
    "\n",
    "for column in residuals.columns:\n",
    "    series = residuals[column]\n",
    "    adf_residuals[f\"{column}_residuals\"] = TimeseriesTests.adf_test(series)\n",
    "    pp_residuals[f\"{column}_residuals\"] = TimeseriesTests.phillips_perron_test(series)\n",
    "    # kpss_residuals[f\"{column}_residuals\"] = TimeseriesTests.kpss_test(series)\n",
    "\n",
    "TimeseriesTests.display_adf_results(adf_residuals)\n",
    "TimeseriesTests.display_pp_results(pp_residuals)\n",
    "# TimeseriesTests.display_kpss_results(kpss_residuals)\n",
    "\n",
    "# Test for Normality in Residuals\n",
    "shapiro_wilk_residuals = {}\n",
    "\n",
    "for column in residuals.columns:\n",
    "    series = residuals[column]\n",
    "    shapiro_wilk_residuals[column] = TimeseriesTests.shapiro_wilk(series) # safe for less than 2000 observations\n",
    "    # TimeseriesTests.qq_plot(series, 'Sample Q-Q Plot')\n",
    "    TimeseriesTests.histogram_ndc(series)\n",
    "    TimeseriesTests.histogram_kde(series)\n",
    "\n",
    "TimeseriesTests.display_shapiro_wilk_results(shapiro_wilk_residuals)\n",
    "\n",
    "# -- TODO: Fix below test and add display function --\n",
    "# Test for Homoscedascity\n",
    "lagged_values = train_data.shift(lag).dropna()\n",
    "\n",
    "bp_results = {}\n",
    "white_results = {}\n",
    "\n",
    "# Perform the Breusch-Pagan test for each series in residuals\n",
    "for column in residuals.columns:\n",
    "    white_results[column] = TimeseriesTests.white_test(np.array(lagged_values[column]), np.array(residuals[column]))\n",
    "    bp_results[column] = TimeseriesTests.breusch_pagan(np.array(lagged_values[column]), np.array(residuals[column]))\n",
    "\n",
    "TimeseriesTests.display_white_test_results(white_results)\n",
    "TimeseriesTests.display_breusch_pagan_results(bp_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12 : Forecast and Model Evaluation \n",
    "forecast, lower, upper = model.predict(steps=len(test_data), alpha=0.05)  # 95% confidence interval\n",
    "forecast_df = pd.DataFrame(data=forecast, index=test_data.index, columns=test_data.columns)\n",
    "\n",
    "TimeseriesTests.evaluate_forecast(test_data, forecast_df)\n",
    "TimeseriesTests.plot_forecast(actual=test_data, forecast=forecast_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13 : Create fitted values(spread) based on long-term equilibrium relationship (V = SUM(aAt + bBt + cCt ...) for i = 0 -> i = n)\n",
    "first_cointegration_vector = johansen_results['Cointegrating Vector'][0]\n",
    "spread = Strategy.create_spread(data, first_cointegration_vector) \n",
    "\n",
    "# Test Stationarity in Spread\n",
    "adf_spread_results = {}\n",
    "pp_spread_results = {}\n",
    "\n",
    "adf_spread_results['spread'] = TimeseriesTests.adf_test(spread)\n",
    "pp_spread_results['spread'] = TimeseriesTests.phillips_perron_test(spread)\n",
    "\n",
    "TimeseriesTests.display_adf_results(adf_spread_results)\n",
    "TimeseriesTests.display_pp_results(pp_spread_results)\n",
    "\n",
    "# Test historical nature of spread w/ Hurst Exponent\n",
    "hurst_exponent_result = TimeseriesTests.hurst_exponent(np.array(spread))\n",
    "print(f\"\\nHurst Exponent : {hurst_exponent_result}\")\n",
    "\n",
    "# Test historical half-life (expected time to mean revert)\n",
    "spread_lagged = DataProcessing.lag_series(spread)\n",
    "spread_combined = pd.DataFrame({'Original': spread, 'Lagged': spread_lagged}).dropna()\n",
    "half_life, residuals = TimeseriesTests.half_life(Y = spread_combined['Original'], Y_lagged = spread_combined['Lagged'])\n",
    "print(f\"\\nHalf-Life : {half_life}\")\n",
    "\n",
    "# Visualize spread/price relationship\n",
    "TimeseriesTests.plot_price_and_spread(price_data = data, spread = pd.Series(spread))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14 :Establish Strategy Rules : utltize johansen for hedge ratios and vecm as an signal indicator\n",
    "z_score_spread = Strategy.calculate_z_score(spread) \n",
    "TimeseriesTests.plot_price_and_spread(price_data = data, spread = pd.Series(z_score_spread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeseriesTests.plot_zscore(pd.Series(z_score_spread))\n",
    "print(type(first_cointegration_vector))\n",
    "Strategy.visualize_spread_formula(data, first_cointegration_vector)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
